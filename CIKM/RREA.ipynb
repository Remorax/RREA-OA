{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import random\n",
    "import tensorflow.keras as keras\n",
    "from tqdm import *\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from CSLS import *\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from layer import NR_GraphAttention\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"2\"\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True  \n",
    "sess = tf.compat.v1.Session(config=config)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512 319\n"
     ]
    }
   ],
   "source": [
    "# lang = 'zh'\n",
    "train_pair,dev_pair,adj_matrix,r_index,r_val,adj_features,rel_features,val_size = load_data('datasets/conference/', window_idx=0, train_ratio=0.30)\n",
    "adj_matrix = np.stack(adj_matrix.nonzero(),axis = 1)\n",
    "rel_matrix,rel_val = np.stack(rel_features.nonzero(),axis = 1),rel_features.data\n",
    "ent_matrix,ent_val = np.stack(adj_features.nonzero(),axis = 1),adj_features.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_size = adj_features.shape[0]\n",
    "rel_size = rel_features.shape[1]\n",
    "triple_size = len(adj_matrix)\n",
    "batch_size = node_size\n",
    "\n",
    "\n",
    "class TokenEmbedding(keras.layers.Embedding):\n",
    "    \"\"\"Embedding layer with weights returned.\"\"\"\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return self.input_dim, self.output_dim\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.embeddings\n",
    "    \n",
    "def get_embedding():\n",
    "    inputs = [adj_matrix,r_index,r_val,rel_matrix,ent_matrix]\n",
    "    inputs = [np.expand_dims(item,axis=0) for item in inputs]\n",
    "    return get_emb.predict_on_batch(inputs)\n",
    "\n",
    "def test(wrank = None):\n",
    "    vec = get_embedding()\n",
    "    return  get_hits(vec,dev_pair,wrank=wrank)\n",
    "\n",
    "def CSLS_test(thread_number = 16, csls=10,accurate = True):\n",
    "    vec = get_embedding()\n",
    "    Lvec = np.array([vec[e1] for e1, e2 in dev_pair])\n",
    "    Rvec = np.array([vec[e2] for e1, e2 in dev_pair])\n",
    "    Lvec = Lvec / np.linalg.norm(Lvec,axis=-1,keepdims=True)\n",
    "    Rvec = Rvec / np.linalg.norm(Rvec,axis=-1,keepdims=True)\n",
    "    eval_alignment_by_sim_mat(Lvec, Rvec, [1], thread_number, csls=csls, accurate=accurate)\n",
    "    return None\n",
    "\n",
    "def get_train_set(batch_size = batch_size):\n",
    "    negative_ratio =  batch_size // len(train_pair) + 1\n",
    "    train_set = np.reshape(np.repeat(np.expand_dims(train_pair,axis=0),axis=0,repeats=negative_ratio),newshape=(-1,2))\n",
    "    np.random.shuffle(train_set); train_set = train_set[:batch_size]\n",
    "    train_set = np.concatenate([train_set,np.random.randint(0,node_size,train_set.shape)],axis = -1)\n",
    "    return train_set\n",
    "\n",
    "def get_trgat(node_size,rel_size,node_hidden,rel_hidden,triple_size,n_attn_heads = 2,dropout_rate = 0,gamma = 3,lr = 0.005,depth = 2):\n",
    "    adj_input = Input(shape=(None,2))\n",
    "    index_input = Input(shape=(None,2),dtype='int64')\n",
    "    val_input = Input(shape = (None,))\n",
    "    rel_adj = Input(shape=(None,2))\n",
    "    ent_adj = Input(shape=(None,2))\n",
    "    \n",
    "    ent_emb = TokenEmbedding(node_size,node_hidden,trainable = True)(val_input) \n",
    "    rel_emb = TokenEmbedding(rel_size,node_hidden,trainable = True)(val_input)\n",
    "    \n",
    "    def avg(tensor,size):\n",
    "        adj = K.cast(K.squeeze(tensor[0],axis = 0),dtype = \"int64\")   \n",
    "        adj = tf.SparseTensor(indices=adj, values=tf.ones_like(adj[:,0],dtype = 'float32'), dense_shape=(node_size,size)) \n",
    "        adj = tf.sparse.softmax(adj) \n",
    "        return tf.sparse.sparse_dense_matmul(adj,tensor[1])\n",
    "    \n",
    "    opt = [rel_emb,adj_input,index_input,val_input]\n",
    "    ent_feature = Lambda(avg,arguments={'size':node_size})([ent_adj,ent_emb])\n",
    "    rel_feature = Lambda(avg,arguments={'size':rel_size})([rel_adj,rel_emb])\n",
    "    \n",
    "    encoder = NR_GraphAttention(node_size,activation=\"relu\",\n",
    "                                       rel_size = rel_size,\n",
    "                                       depth = depth,\n",
    "                                       attn_heads=n_attn_heads,\n",
    "                                       triple_size = triple_size,\n",
    "                                       attn_heads_reduction='average',   \n",
    "                                       dropout_rate=dropout_rate)\n",
    "    \n",
    "    out_feature = Concatenate(-1)([encoder([ent_feature]+opt),encoder([rel_feature]+opt)])\n",
    "    out_feature = Dropout(dropout_rate)(out_feature)\n",
    "    \n",
    "    alignment_input = Input(shape=(None,4))\n",
    "    find = Lambda(lambda x:K.gather(reference=x[0],indices=K.cast(K.squeeze(x[1],axis=0), 'int32')))([out_feature,alignment_input])\n",
    "    \n",
    "    def align_loss(tensor):\n",
    "        def _cosine(x):\n",
    "            dot1 = K.batch_dot(x[0], x[1], axes=1)\n",
    "            dot2 = K.batch_dot(x[0], x[0], axes=1)\n",
    "            dot3 = K.batch_dot(x[1], x[1], axes=1)\n",
    "            max_ = K.maximum(K.sqrt(dot2 * dot3), K.epsilon())\n",
    "            return dot1 / max_\n",
    "        \n",
    "        def l1(ll,rr):\n",
    "            return K.sum(K.abs(ll-rr),axis=-1,keepdims=True)\n",
    "        \n",
    "        def l2(ll,rr):\n",
    "            return K.sum(K.square(ll-rr),axis=-1,keepdims=True)\n",
    "        \n",
    "        l,r,fl,fr = [tensor[:,0,:],tensor[:,1,:],tensor[:,2 ,:],tensor[:,3,:]]\n",
    "        loss = K.relu(gamma + l1(l,r) - l1(l,fr)) + K.relu(gamma + l1(l,r) - l1(fl,r))\n",
    "        return tf.compat.v1.reduce_sum(loss,keep_dims=True) / (batch_size)\n",
    "    \n",
    "    loss = Lambda(align_loss)(find)\n",
    "    \n",
    "    inputs = [adj_input,index_input,val_input,rel_adj,ent_adj]\n",
    "    train_model = keras.Model(inputs = inputs + [alignment_input],outputs = loss)\n",
    "    train_model.compile(loss=lambda y_true,y_pred: y_pred,optimizer=keras.optimizers.RMSprop(lr))\n",
    "    \n",
    "    feature_model = keras.Model(inputs = inputs,outputs = out_feature)\n",
    "    return train_model,feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method TokenEmbedding.call of <__main__.TokenEmbedding object at 0x7f38346d64d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method NR_GraphAttention.call of <layer.NR_GraphAttention object at 0x7f384c164c90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_embedding (TokenEmbedding (512, 100)           51200       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "token_embedding_1 (TokenEmbeddi (638, 100)           63800       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (512, 100)           0           input_5[0][0]                    \n",
      "                                                                 token_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 2)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (512, 100)           0           input_4[0][0]                    \n",
      "                                                                 token_embedding_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "nr__graph_attention (NR_GraphAt (512, 300)           600         lambda[0][0]                     \n",
      "                                                                 token_embedding_1[0][0]          \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 token_embedding_1[0][0]          \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (512, 600)           0           nr__graph_attention[0][0]        \n",
      "                                                                 nr__graph_attention[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (512, 600)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, None, 4)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 4, 600)       0           dropout[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (1, 1)               0           lambda_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 115,600\n",
      "Trainable params: 115,600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model,get_emb = get_trgat(dropout_rate=0.30,node_size=node_size,rel_size=rel_size,n_attn_heads = 1,depth=2,gamma =3,node_hidden=100,rel_hidden = 100,triple_size = triple_size)\n",
    "model.summary(); initial_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 start.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f383478fcb0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function get_trgat.<locals>.<lambda> at 0x7f383472ab90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1200 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[347,0] = 514 is not in [0, 512)\n\t [[node model/lambda_2/GatherV2 (defined at <ipython-input-3-c1367efc1c80>:76) ]] [Op:__inference_train_function_2949]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/lambda_2/GatherV2:\n model/dropout/dropout/Mul_1 (defined at <ipython-input-5-0375442f1a51>:13)\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0375442f1a51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0madj_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrel_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ment_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m300\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mCSLS_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1725\u001b[0m                                                     class_weight)\n\u001b[1;32m   1726\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  indices[347,0] = 514 is not in [0, 512)\n\t [[node model/lambda_2/GatherV2 (defined at <ipython-input-3-c1367efc1c80>:76) ]] [Op:__inference_train_function_2949]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model/lambda_2/GatherV2:\n model/dropout/dropout/Mul_1 (defined at <ipython-input-5-0375442f1a51>:13)\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "rest_set_1 = [e1 for e1, e2 in dev_pair]\n",
    "rest_set_2 = [e2 for e1, e2 in dev_pair]\n",
    "np.random.shuffle(rest_set_1)\n",
    "np.random.shuffle(rest_set_2)\n",
    "\n",
    "epoch = 1200\n",
    "for turn in range(5):\n",
    "    print(\"iteration %d start.\"%turn)\n",
    "    for i in trange(epoch):\n",
    "        train_set = get_train_set()\n",
    "        inputs = [adj_matrix,r_index,r_val,rel_matrix,ent_matrix,train_set]\n",
    "        inputs = [np.expand_dims(item,axis=0) for item in inputs]\n",
    "        model.train_on_batch(inputs,np.zeros((1,1)))\n",
    "        if i%300 == 299:\n",
    "            CSLS_test()\n",
    "\n",
    "    new_pair = []\n",
    "    vec = get_embedding()\n",
    "    Lvec = np.array([vec[e] for e in rest_set_1])\n",
    "    Rvec = np.array([vec[e] for e in rest_set_2])\n",
    "    Lvec = Lvec / np.linalg.norm(Lvec,axis=-1,keepdims=True)\n",
    "    Rvec = Rvec / np.linalg.norm(Rvec,axis=-1,keepdims=True)\n",
    "    A,_ = eval_alignment_by_sim_mat(Lvec, Rvec, [1], 16,10,True,False)\n",
    "    B,_ = eval_alignment_by_sim_mat(Rvec, Lvec,[1], 16,10,True,False)\n",
    "    A = sorted(list(A)); B = sorted(list(B))\n",
    "    for a,b in A:\n",
    "        if  B[b][1] == a:\n",
    "            new_pair.append([rest_set_1[a],rest_set_2[b]])\n",
    "    print(\"generate new semi-pairs: %d.\" % len(new_pair))\n",
    "    \n",
    "    train_pair = np.concatenate([train_pair,np.array(new_pair)],axis = 0)\n",
    "    for e1,e2 in new_pair:\n",
    "        if e1 in rest_set_1:\n",
    "            rest_set_1.remove(e1) \n",
    "        \n",
    "    for e1,e2 in new_pair:\n",
    "        if e2 in rest_set_2:\n",
    "            rest_set_2.remove(e2) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  3, 472,  88,  24],\n",
       "        [264,  92, 500, 241],\n",
       "        [143, 386, 356,  53],\n",
       "        ...,\n",
       "        [217,  81, 443,  96],\n",
       "        [476, 277, 108, 486],\n",
       "        [ 13, 386, 476, 433]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
